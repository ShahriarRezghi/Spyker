{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b949fbd",
   "metadata": {},
   "source": [
    "# Tutorial 4: Other Functionalities\n",
    "In this tutorial we show how different parts of the API work. First we import the need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e29ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spyker\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bc21b8",
   "metadata": {},
   "source": [
    "We start this tutorials by Spyker tensors and how to convert them to and back from PyTorch tensors and Numpy arrays. Spyker tensors only support 32-bit floating point and 8-bit unsigned integer numbers on CPUs and CUDA GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec647f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.rand(10, 10, dtype=torch.float32) # random pytorch tensor\n",
    "B = np.random.random([10, 10]).astype(np.float32) # random numpy array\n",
    "C = spyker.to_tensor(A) # convert tensor A into a spyker tensor\n",
    "D = spyker.to_tensor(B) # convert array B into spyker tensor\n",
    "E = spyker.to_torch(C) # convert spyker tensor to numpy array\n",
    "F = spyker.to_numpy(D) # convert spyker tensor to pytorch tensor\n",
    "print(torch.allclose(A, E))\n",
    "print(np.allclose(B, F))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27ea970",
   "metadata": {},
   "source": [
    "Spyker also has a `Sparse` container that can only contain 5D binary sparse values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8784616",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = (torch.rand(1, 1, 1, 10, 10) > .95).to(torch.uint8) # random 5D values\n",
    "B = spyker.to_sparse(A) # convert to sparse\n",
    "print(B.sparsity()) # print the sparsity of the data\n",
    "C = spyker.to_torch(B.dense())\n",
    "print(A.allclose(C))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c381b6bf",
   "metadata": {},
   "source": [
    "Some of the modules of Spyker need to generate random data. You can set the seed of this random generation by `spyker.random_seed` function which takes in an integer seed. Some of the operations that Spyker performs need additional storage that needs to ba cached. These cached data don't get removed automatically and stay until the end of program. If you need to clear all of these cached data, you can use `spyker.clear_context` function. There is also a function that forces cuDNN to allocate less memory for the convolution operations which can be set with `spyker.light_conv`which takes in a boolean value setting it to true or false."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807db5e9",
   "metadata": {},
   "source": [
    "There are some information that you can get when you want to use the CUDA device. First, we want to know if cuda is available (your setup is correct and your build of Spyker supports your hardware)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61cb5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Is CUDA available?', spyker.cuda_available())\n",
    "print('Count of CUDA devices you have:', spyker.cuda_device_count())\n",
    "print('Supported CUDA architectures of your Spyker build:', spyker.cuda_arch_list())\n",
    "print('Architectures of your cuda devices', spyker.cuda_device_arch())\n",
    "print('Total memory avialable of current CUDA device:', spyker.cuda_memory_total())\n",
    "print('free memory avialable of current CUDA device:', spyker.cuda_memory_free())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbe166a",
   "metadata": {},
   "source": [
    "You can change the CUDA device that you are using by passing the index of your device `spyker.cuda_set_device` function. An important optimization that Spyker uses is caching cuda memory. This is enabled by default and can be changed using `spyker.cuda_cache_enable` which takes in a boolean value. We can see how this cache works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de3b411",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GPU memory Taken: ', spyker.cuda_memory_taken())\n",
    "print('GPU memory Used', spyker.cuda_memory_used())\n",
    "A = spyker.create_tensor(spyker.device('cuda'), 'f32', [10, 10]) # empty tensor\n",
    "print('GPU memory Taken: ', spyker.cuda_memory_taken())\n",
    "print('GPU memory Used', spyker.cuda_memory_used())\n",
    "del A\n",
    "print('GPU memory Taken: ', spyker.cuda_memory_taken())\n",
    "print('GPU memory Used', spyker.cuda_memory_used())\n",
    "spyker.cuda_cache_clear()\n",
    "print('GPU memory Taken: ', spyker.cuda_memory_taken())\n",
    "print('GPU memory Used', spyker.cuda_memory_used())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4730eb7",
   "metadata": {},
   "source": [
    "As we can see when we clear the cuda cache, the memory used drops back to zero, but the memory taken doesn't. We can also see a summary of the cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bfe346",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = spyker.create_tensor(spyker.device('cuda'), 'f32', [10, 10])\n",
    "B = spyker.create_tensor(spyker.device('cuda'), 'f32', [5, 5])\n",
    "C = spyker.create_tensor(spyker.device('cuda'), 'f32', [2, 2])\n",
    "spyker.cuda_cache_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
