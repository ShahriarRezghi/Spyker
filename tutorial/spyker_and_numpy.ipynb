{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b3e8474",
   "metadata": {},
   "source": [
    "# Tutorial 2: Spyker and Numpy\n",
    "This tutorial follows the previous tutoral on how to use the library and its interaction with PyTorch. In this tutorial we will see how to use the library with Numpy to classify the MNIST dataset. First We start with importing the needed tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4437e255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spyker\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb96a9e",
   "metadata": {},
   "source": [
    "We need to load the data as in batches to speed up the process. So we define the `Dataset` class that iterates over the dataset batch by batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce17929",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, data, target, batch):\n",
    "        self.data = data\n",
    "        self.target = target\n",
    "        self.batch = batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return (self.data.shape[0] + self.batch - 1) // self.batch\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index >= len(self): raise StopIteration\n",
    "        start = index * self.batch\n",
    "        end = min(start + self.batch, self.data.shape[0])\n",
    "        return spyker.to_tensor(self.data[start:end]), self.target[start:end]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c920ac1",
   "metadata": {},
   "source": [
    "Then we can wrap the training and testing sets with our `Dataset` class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8aa61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch, root = 64, './MNIST'\n",
    "trainx, trainy, testx, testy = spyker.read_mnist(\n",
    "    root+'/train-images-idx3-ubyte', root+'/train-labels-idx1-ubyte',\n",
    "    root+'/t10k-images-idx3-ubyte', root+'/t10k-labels-idx1-ubyte')\n",
    "trainx, trainy, testx, testy = spyker.to_numpy(trainx, trainy, testx, testy)\n",
    "train = Dataset(trainx, trainy, batch)\n",
    "test = Dataset(testx, testy, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc36842",
   "metadata": {},
   "source": [
    "The `Transform` and `Network` classes are the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39026568",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.filter = spyker.LoG(3, [.5, 1, 2], pad=3, device=device)\n",
    "    \n",
    "    def __call__(self, input):\n",
    "        input = input.to(self.device)\n",
    "        return spyker.code(spyker.threshold(self.filter(input), .01), 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1918944",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    def __init__(self, device):\n",
    "        self.conv1 = spyker.Conv(6, 50, 5, pad=2, device=device)\n",
    "        self.conv2 = spyker.Conv(50, 100, 3, pad=1, device=device)\n",
    "        self.conv1.stdpconfig = [spyker.STDPConfig(.004, -.003)]\n",
    "        self.conv2.stdpconfig = [spyker.STDPConfig(.004, -.003)]\n",
    "    \n",
    "    def train1(self, input):\n",
    "        output = spyker.inhibit(spyker.threshold(self.conv1(input), 16))\n",
    "        self.conv1.stdp(input, spyker.convwta(output, 3, 5), spyker.fire(output))\n",
    "        \n",
    "    def train2(self, input):\n",
    "        input = spyker.pool(spyker.fire(self.conv1(input), 16), 2)\n",
    "        output = spyker.inhibit(spyker.threshold(self.conv2(input), 5))\n",
    "        self.conv2.stdp(input, spyker.convwta(output, 1, 8), spyker.fire(output))\n",
    "    \n",
    "    def __call__(self, input):\n",
    "        input = spyker.pool(spyker.fire(self.conv1(input), 16), 2)\n",
    "        input = spyker.pool(spyker.fire(self.conv2(input), 5), 3)\n",
    "        input = 15 - spyker.to_numpy(spyker.gather(input))\n",
    "        return input.reshape(input.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b0ca1d",
   "metadata": {},
   "source": [
    "We will use `Numpy` to concatenate the output tensors in the `Total` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751ab659",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Total(network, transform, dataset):\n",
    "    data_total, target_total = [], []\n",
    "    for data, target in dataset:\n",
    "        data_total.append(network(transform(data)))\n",
    "        target_total.append(target)\n",
    "    return np.concatenate(data_total), np.concatenate(target_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce2591e",
   "metadata": {},
   "source": [
    "The rest are the same as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c41a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Update(config):\n",
    "    rate = config.negative / config.positive\n",
    "    pos = min(config.positive * 2, .1)\n",
    "    config.positive, config.negative = pos, pos * rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5788dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = spyker.device('cuda' if spyker.cuda_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0548d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Transform(device)\n",
    "network = Network(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb22084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "for i, (data, _) in enumerate(tqdm(train, \"Training Layer 1\")):\n",
    "    if (i + 1) % 10 == 0: Update(network.conv1.stdpconfig[0])\n",
    "    network.train1(transform(data))\n",
    "spyker.quantize(network.conv1.kernel, 0, .5, 1)\n",
    "\n",
    "for i, (data, _) in enumerate(tqdm(train, \"Training Layer 2\")):\n",
    "    if (i + 1) % 10 == 0: Update(network.conv2.stdpconfig[0])\n",
    "    network.train2(transform(data))\n",
    "spyker.quantize(network.conv2.kernel, 0, .5, 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c04d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_target = Total(network, transform, train)\n",
    "test_data, test_target = Total(network, transform, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4e085",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=200).fit(train_data, train_target)\n",
    "train_data, test_data = pca.transform(train_data), pca.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ba6ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = SVC(C=2.4).fit(train_data, train_target).predict(test_data)\n",
    "accuracy = (target == test_target).sum() / len(test_target)\n",
    "print(f\"Final Accuracy: {accuracy * 100 :.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccad1ca5",
   "metadata": {},
   "source": [
    "This implementation might run faster than in the previous tutorial. This might be because we access the datasets directly instead of having TorchVision's MNIST dataset convert them to PIL images and back."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
